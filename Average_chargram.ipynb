{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Average_chargram.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R6W7IXs3LU2"
      },
      "source": [
        "!wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06QhJ7G0-Vn9"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import gensim\n",
        "from gensim import utils\n",
        "from nltk import word_tokenize\n",
        "from nltk import download\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF39IefR-XLY"
      },
      "source": [
        "word_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLGbb3-e-DGF"
      },
      "source": [
        "def document_vector(word2vec_model, doc):\n",
        "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
        "    if(len(doc)==0):\n",
        "      return [0]*300\n",
        "    return np.mean(word2vec_model[doc], axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99bV064I30PH"
      },
      "source": [
        "download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkEGvLh-J_4v"
      },
      "source": [
        "file1 = open('MR.x.train.txt', 'r',encoding='ISO-8859-1') \n",
        "Lines = file1.readlines() \n",
        "Lines[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKIm1YlTRLqY"
      },
      "source": [
        "file1 = open('MR.x.test.txt', 'r',encoding='ISO-8859-1') \n",
        "Lines3 = file1.readlines() \n",
        "Lines3[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpMdbSaP85Kc"
      },
      "source": [
        "list_of_sentence=[]\n",
        "preprocessed_texts=[lines.lower() for lines in Lines]\n",
        "for j in range(len(preprocessed_texts)):\n",
        "  temp=[] \n",
        "  for chars in range(2,15):\n",
        "    for i in range(len(preprocessed_texts[j])-chars):\n",
        "      seq = str(preprocessed_texts[j][i:i+chars])\n",
        "      temp.append(seq)\n",
        "  list_of_sentence.append(temp)\n",
        "n=len(list_of_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_H3ggQQ9GLF"
      },
      "source": [
        "list_of_sentence[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ-0lWFtRxPE"
      },
      "source": [
        "list_of_sentence3=[]\n",
        "preprocessed_texts3=[lines.lower() for lines in Lines3]\n",
        "for j in range(len(preprocessed_texts3)):\n",
        "  temp=[] \n",
        "  for chars in range(2,15):\n",
        "    for i in range(len(preprocessed_texts3[j])-chars):\n",
        "      seq = str(preprocessed_texts3[j][i:i+chars])\n",
        "      temp.append(seq)\n",
        "  list_of_sentence3.append(temp)\n",
        "n=len(list_of_sentence3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plhzh0IG9Ysl"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "file1 = open('MR.y.train.txt', 'r') \n",
        "Lines = file1.readlines() \n",
        "count = 0\n",
        "target1=[]\n",
        "for line in Lines: \n",
        "    target1.append(line)\n",
        "le = LabelEncoder()\n",
        "le.fit([\"NEG\\n\", \"POS\\n\"])\n",
        "list(le.classes_)\n",
        "labels=le.transform(target1)\n",
        "labels[:29]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogg954elB7d6"
      },
      "source": [
        "pos=0\n",
        "for i in labels:\n",
        "  if(i==0):\n",
        "    pos+=1\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXp_WPaY9lXl"
      },
      "source": [
        "corpus=list_of_sentence\n",
        "texts=Lines\n",
        "y=labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz3ylT-ZSDZb"
      },
      "source": [
        "corpus3=list_of_sentence3\n",
        "texts3=Lines3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGan60QT997Y"
      },
      "source": [
        "x =[]\n",
        "for doc in corpus: \n",
        "    x.append(document_vector(word_model, doc))\n",
        "X = np.array(x) \n",
        "X.shape, len(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-_c9Y1yA-1C"
      },
      "source": [
        "x3 =[]\n",
        "for doc in corpus3: \n",
        "    x3.append(document_vector(word_model, doc))\n",
        "X3 = np.array(x3)           #\n",
        "X3.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6wkZVdyLUcS"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgMfuaWrLP9r"
      },
      "source": [
        "train_x=X\n",
        "train_y=y\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(train_x, train_y, test_size=0.20, random_state=42)\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "Y_train=tf.convert_to_tensor(Y_train, dtype=tf.float32)\n",
        "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
        "Y_val=tf.convert_to_tensor(Y_val, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eKbc7nWDPJj"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "clf = LogisticRegressionCV(cv=6, max_iter=1000,random_state=0,multi_class='ovr').fit(X_train, Y_train)\n",
        "score = clf.score(X_val, Y_val)\n",
        "\n",
        "print(\"Accuracy:\", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9chdbMiDXpF"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scale=StandardScaler()\n",
        "scale.fit(X_train)\n",
        "X_train=scale.transform(X_train)\n",
        "X_val=scale.transform(X_val)\n",
        "train_x=scale.transform(train_x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeifGJsyDZvf"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression(max_iter=1000,random_state=0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "score = classifier.score(X_val, Y_val)\n",
        "\n",
        "print(\"Accuracy:\", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmMW3nn8Va8V"
      },
      "source": [
        "y_pred=classifier.predict(X3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNVZsFixQTRl"
      },
      "source": [
        "print(y_pred[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dM45aqdCnUf"
      },
      "source": [
        "pos=0\n",
        "for i in y_pred:\n",
        "  if(i==1):\n",
        "    pos+=1\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNPnCIUbdJYU"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(300, input_dim=300, activation='linear'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic44v1xPd7xr"
      },
      "source": [
        "history=model.fit(X_train, Y_train, validation_data=(X_val,Y_val), epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKJx1hRpe7hF"
      },
      "source": [
        "y_pred2=model.predict_classes(X3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "217ipGfBDRnW"
      },
      "source": [
        "pos=0\n",
        "for i in y_pred2:\n",
        "  if(i==1):\n",
        "    pos+=1\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4e3N5lzMutV"
      },
      "source": [
        "print(y_pred2[:12])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-vElBbUqu93"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86TL57WwxXQW"
      },
      "source": [
        "score=model.evaluate(X_val,Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CivyWUl2gcdP"
      },
      "source": [
        "Y_test=[]\n",
        "for i in range(len(y_pred)):\n",
        "  if(y_pred[i]==0):\n",
        "    Y_test.append('NEG')\n",
        "    continue\n",
        "  if(y_pred[i]==1):\n",
        "    Y_test.append('POS')\n",
        "    continue\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_MG1gwpgoJT"
      },
      "source": [
        "f1 = open(\"char2.MR.y.test.txt\", \"w\")\n",
        "for y in Y_test:\n",
        "  y1=str(y)\n",
        "  f1.write(str(y1))\n",
        "  f1.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dUIJxPXgshC"
      },
      "source": [
        "f2=open(\"char2.MR.y.test.txt\",\"r\")\n",
        "for x in f2:\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}